{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powerfolio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo.png\" width=\"150\" title=\"stock_flex\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependancies\n",
    "Import system, data analytics, finance API, database tools, and visualization libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'finnhub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-19dfcc4c1667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malpaca_trade_api\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtradeapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquandl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfinnhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'finnhub'"
     ]
    }
   ],
   "source": [
    "# System\n",
    "import os\n",
    "import time, sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from datetime import date, datetime, timedelta\n",
    "from ast import literal_eval as make_tuple\n",
    "\n",
    "# Data analytics\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, MultiIndex\n",
    "from typing import List, NewType\n",
    "import numpy as np\n",
    "\n",
    "# Database tools\n",
    "import sqlite3\n",
    "\n",
    "# Visualization\n",
    "import panel as pn\n",
    "import panel.widgets as pnw\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "pn.extension('plotly')\n",
    "pn.extension()\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Finance\n",
    "import alpaca_trade_api as tradeapi\n",
    "import quandl as ql\n",
    "import finnhub\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Local dependancies\n",
    "import MyPortfolioSimulator as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Connections\n",
    "- Static Data Connections\n",
    "- Dynamic Data Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Data Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stock Ticker Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get tickers within S&P500 index\n",
    "sp500_tickers_path = Path('resources/sp500_tickers.csv')\n",
    "sp500_tickers = pd.read_csv(sp500_tickers_path).sort_values(by=\"Symbol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S&P 500 ticker list test\n",
    "sp500_tickers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fundamental data from csv\n",
    "stock_fundamentals_data_path = Path(\"resources/fundamental_data.csv\")\n",
    "stock_fundamentals_df = pd.read_csv(stock_fundamentals_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fundamental values test\n",
    "stock_fundamentals_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Data Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alpaca API connector\n",
    "load_dotenv(\"../resources/api_keys.env\")\n",
    "\n",
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Create the Alpaca API object\n",
    "api = tradeapi.REST(\n",
    "alpaca_api_key,\n",
    "alpaca_secret_key,\n",
    "api_version = \"v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Alpaca Trade API key\n",
    "type(alpaca_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Alpaca Trade API secret key\n",
    "type(alpaca_secret_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fundamental Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FinnHub API connector\n",
    "load_dotenv(\"../resources/api_keys.env\")\n",
    "\n",
    "# Set FinnBug API key\n",
    "finnhub_api_key = os.getenv(\"FINNHUB_API_KEY\")\n",
    "\n",
    "# Create FinnHub API object\n",
    "finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
    "\n",
    "# Method to obtain json data from FinnHub\n",
    "def finnhub_data(ticker):\n",
    "    \n",
    "    data = finnhub_client.company_basic_financials(ticker, \"\")\n",
    "    data_df = pd.DataFrame(data)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "type(finnhub_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bond Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treasury bonds\n",
    "def treasury_data():\n",
    "    return ql.get(\"USTREASURY/YIELD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quandl treasure data test\n",
    "treasury_data().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stock Data Parsing Methods\n",
    "A collection of methods for parsing S&P 500 tickers, calling Alpaca Trade API, and querying stock_prices.db database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alpaca API Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get prices for tickers withing a given index or sector\n",
    "def stock_prices_from_api(ticker_list, start_date, end_date):\n",
    "    '''Returns pd.DataFrame with prices for the given tickers\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tickers_df : pd.DataFrame - contains tickers for given index or sector under \n",
    "        the \"Symbol\" column which is the DataFrame key\n",
    "    start_date : str() - string with date in following format YYYY-MM-DD\n",
    "    end_date: str() - string with date in following format YYYY-MM-DD \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame with securities price data\n",
    "    '''\n",
    "   \n",
    "    # Get list of tickers from the tickers_df list or tickers_df DataFrame \n",
    "    tickers = ticker_list\n",
    "    \n",
    "    # Parse start and end dates\n",
    "    start_date = pd.Timestamp(start_date, tz=\"America/New_York\").isoformat()\n",
    "    end_date = pd.Timestamp(end_date, tz=\"America/New_York\").isoformat()\n",
    "    \n",
    "    # Connect to Alpaca API and get data\n",
    "    \"\"\"Condition handling: \n",
    "        a. Alpaca API 422 Client Error if more than 100 tickers are passed - COMPLETE\n",
    "        b. Alpaca API data max row limit of 1000 - PENDING\"\"\"\n",
    "    \n",
    "    \n",
    "    # a. Alpaca API condition handling, sending 100 tickers at a time\n",
    "    # Declate a pd.DataFrame\n",
    "    result_df = pd.DataFrame()\n",
    "    tickers_n = 50\n",
    "    \n",
    "    for i in range(0, len(tickers), tickers_n):\n",
    "        # Slice the ticker list into lists of 50 tickers\n",
    "        sliced_tickers = tickers[i:i + tickers_n] \n",
    "        \n",
    "        temp_df = api.get_barset(\n",
    "        sliced_tickers,\n",
    "        timeframe = \"1D\",\n",
    "        start = start_date,\n",
    "        end = end_date,\n",
    "        limit = 1000).df\n",
    "\n",
    "        # Append temporary dataframe to result_df\n",
    "        result_df = pd.concat([result_df, temp_df], axis = \"columns\", join = \"outer\")\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alpaca Trade API stock data test\n",
    "stock_prices = stock_prices_from_api(list(sp500_tickers.head(10)[\"Symbol\"]), \"2020-05-01\", '2021-05-13')\n",
    "stock_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Multiindex slicing\n",
    "idx = pd.IndexSlice\n",
    "index = list(stock_prices.transpose().index.get_level_values(0))\n",
    "formatted_stock_prices = stock_prices.xs('close', axis=1, level=1, drop_level=False).droplevel(1, axis=1)\n",
    "formatted_stock_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Local <code>stock_price.db</code> Database Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rebuilds database for Alpaca API stock prices if necessary\n",
    "def create_stock_prices_db():\n",
    "    '''This method creates a SQLite database that will store all of ticker daily prices;\n",
    "    This method is created to resolve the Alpaca API request limits that can greatly slow down large data requests\n",
    "    '''\n",
    "    \n",
    "    print(\"This will restore the 'stock_prices' database and delete all of stored values, are you sure? y/[n]\")\n",
    "\n",
    "    conn = sqlite3.connect('resources/stock_prices.db')\n",
    "    \n",
    "    \n",
    "# Seed stock price database\n",
    "def seed_stock_prices_database(tickers_df):\n",
    "    '''Seeds stock_prices database that houses all prices for tickers within an index or sector'''\n",
    "\n",
    "    # Get data for dates indicated\n",
    "    data = stock_prices_from_api(tickers_df, \"2015-01-01\", \"2018-01-01\")\n",
    "    \n",
    "    # Transpose dataframe\n",
    "    data = data.transpose()\n",
    "    \n",
    "    # Connect to databse\n",
    "    conn = sqlite3.connect('resources/stock_prices.db') \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Iterate over dataframe and populate the database\n",
    "    for ticker, sub_frame in data.groupby(level=0):\n",
    "        \n",
    "        ticker = \"_\" + ticker.replace('.','_')\n",
    "        \n",
    "        list_of_tables = c.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{ticker}';\").fetchall()\n",
    "        if list_of_tables == []:\n",
    "            sub_frame.transpose().to_sql(ticker, conn, if_exists='append')\n",
    "        else:\n",
    "            sub_frame.transpose().to_sql(ticker, conn, if_exists='append')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "    \n",
    "\n",
    "# Update stock price database     \n",
    "def update_stock_prices_database(tickers_df):\n",
    "    '''Updates stock_prices database that houses all prices for tickers within an index or sector'''\n",
    "    \n",
    "    # Get today's date\n",
    "    today_date = date.today().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Connect to databse\n",
    "    conn = sqlite3.connect('resources/stock_prices.db') \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Iterate over dataframe and populate the database\n",
    "    ticker_count = 0\n",
    "    for index, ticker_data in tickers_df.iterrows():\n",
    "        \n",
    "        ticker = \"_\" + ticker_data[\"Symbol\"].replace('.','_')\n",
    "        \n",
    "        # Get list of all tables in databse\n",
    "        list_of_tables = c.execute(f\"SELECT name FROM sqlite_master WHERE type='table' AND name='{ticker}';\").fetchall()\n",
    "        \n",
    "        # If table does not exist, create and seed\n",
    "        if list_of_tables == []: # If tables does not exist\n",
    "            # Get data from Alpaca API\n",
    "            data = stock_prices_from_api(ticker_data, \"2015-01-01\", \"2018-01-01\")\n",
    "            \n",
    "            # Write stock data to databse\n",
    "            data.to_sql(ticker, conn, if_exists='append')\n",
    "            \n",
    "        else: # If table does exist\n",
    "            try:\n",
    "                # Get last date from the table\n",
    "                last_date = c.execute(f\"SELECT time FROM {ticker} ORDER BY time DESC LIMIT 1\").fetchall()\n",
    "                last_date = ''.join(last_date[0]).split(\" \")[0]\n",
    "\n",
    "                # Get next date\n",
    "                next_date = datetime.strptime(last_date, '%Y-%m-%d') + timedelta(days=1)\n",
    "\n",
    "                # Change date format for Alpaca\n",
    "                next_date = next_date.strftime(\"%Y-%m-%d\")\n",
    "                \n",
    "                # Get today's date\n",
    "                today_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "                \n",
    "                if last_date < today_date:\n",
    "\n",
    "                    # Get data from Alpaca API\n",
    "                    data = stock_prices_from_api(ticker_data, last_date, today_date)\n",
    "\n",
    "                    # Write data to database\n",
    "                    data.to_sql(ticker, conn, if_exists='append')\n",
    "                \n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        ticker_count += 1\n",
    "    print(f\"Processing {ticker} | {ticker_count}/{len(tickers_df.index)}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "# Get stock prices from database\n",
    "def stock_prices_from_db(ticker_df, start_date, end_date):\n",
    "    '''Returns a pd.DataFrame with stock price data for tickers passed in ticker_df and \n",
    "    filtered by dates passed in start_date and end_date\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tickers_df : pd.DataFrame - contains tickers for given index or sector under \n",
    "        the \"Symbol\" column which is the DataFrame key\n",
    "    start_date : str() - string with date in following format YYYY-MM-DD\n",
    "    end_date: str() - string with date in following format YYYY-MM-DD \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame with securities price data\n",
    "    '''\n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('resources/stock_prices.db') \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Cast dates to pandas datetime\n",
    "    start_date = pd.Timestamp(start_date, tz=\"America/New_York\").isoformat()\n",
    "    end_date = pd.Timestamp(end_date, tz=\"America/New_York\").isoformat()\n",
    "    \n",
    "    # Declare result_df\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Iterate over tickers\n",
    "    for ticker in list(ticker_df[\"Symbol\"]):\n",
    "        \n",
    "        try:\n",
    "            # Parse ticker name\n",
    "            _ticker = \"_\" + ticker.replace('.','_')\n",
    "\n",
    "            # Query databse\n",
    "            data = pd.read_sql_query(f\"SELECT * FROM {_ticker}\", conn)\n",
    "\n",
    "            # Filter database by dates\n",
    "            data = data[(data['time'] >= start_date) & (data['time'] <= end_date)].set_index(['time'])\n",
    "\n",
    "            # Concatenate dataframes\n",
    "            result_df = pd.concat([result_df, data], axis = \"columns\", join = \"outer\")\n",
    "        \n",
    "        except:\n",
    "            print(f\"Ticker {ticker} not found in database.\")\n",
    "        \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "        \n",
    "    # Create a multi-index \n",
    "    ## Transpose the df\n",
    "    result_df = result_df.transpose()\n",
    "    \n",
    "    ## Get dataframe keys\n",
    "    keys = []\n",
    "    for key in result_df.index:\n",
    "        keys.append(make_tuple(key))\n",
    "\n",
    "    ## Build an index\n",
    "    index = pd.MultiIndex.from_tuples(keys, names=('Symbol', 'Data'))\n",
    "\n",
    "    ## Set index\n",
    "    result_df = result_df.set_index(index).transpose()\n",
    "        \n",
    "    return result_df\n",
    "\n",
    "\n",
    "# Get database date-range\n",
    "def get_db_daterange():\n",
    "    \n",
    "    # Connect to database\n",
    "    conn = sqlite3.connect('resources/stock_prices.db') \n",
    "    c = conn.cursor()\n",
    "    \n",
    "    last_date = pd.read_sql_query(\"SELECT time FROM _MSFT ORDER BY time DESC LIMIT 1\", conn)['time'][0].split(\" \")[0]\n",
    "    \n",
    "    first_date = pd.read_sql_query(\"SELECT time FROM _MSFT ORDER BY time ASC LIMIT 1\", conn)['time'][0].split(\" \")[0]\n",
    "    \n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return (first_date, last_date)\n",
    "\n",
    "def offline_application_set_up():\n",
    "    '''Helper method - sets up offline access to Dashboard'''\n",
    "    create_stock_prices_db()\n",
    "    seed_stock_prices_database(sp500_tickers)\n",
    "    update_stock_prices_database(sp500_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Technical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical Data Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI method : Calculate the RSI indicator\n",
    "def rsi_table (df, days):\n",
    "    '''Returns a pd.DataFrame with Relative Strength Index (RSI) column appended\n",
    "        RSI formula = 100 â€“ (100 / (1 + RS) or can also use 100 * up / (Up + Down)\n",
    "        Where RS (relative strengh)  = Up / Down\n",
    "        Where Up = rolling average price up over the time window obeserved\n",
    "        Where Down = rolling average price down over the time window obeserved\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame - dataframe to be processed\n",
    "        days : int() - numbers of days for RSI calcualtion\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        result_df : pd.DataFrame - dataframe with RSI column appended, calcualted daily for \n",
    "        timeperiod specified by days\n",
    "    '''\n",
    "    \n",
    "    # Filter datafrance to clumn \"close\" only to facilitate the calculs\n",
    "    stocks_close = df.iloc[:,df.columns.get_level_values(1)=='close']\n",
    "    # Swap the column multilevel index to facilitate the calculs\n",
    "    stocks_close = stocks_close.swaplevel(0,1,axis=1)\n",
    "    \n",
    "    # Calculate the movement on the price compared to the previous day closing price\n",
    "    movement_1d = stocks_close - stocks_close.shift(1)\n",
    "    movement_1d.rename(columns={'close':'movement_1d'}, level=0, inplace=True)\n",
    "\n",
    "    # Define a sub-function to calculate the RSI\n",
    "    def rsi (price):\n",
    "        up = price[price>0].mean()\n",
    "        down = abs(price[price<0]).mean()\n",
    "        return 100 * up / (up + down)\n",
    "        \n",
    "    # Calculate the RSI and add it to a dataframe\n",
    "    rsi_df = movement_1d.rolling(window=days).apply(rsi)\n",
    "    rsi_df.rename(columns={'movement_1d':'RSI'}, level=0, inplace=True)\n",
    "    \n",
    "    # Remove the first dates that return NaN from the rolling days calculation\n",
    "    rsi_df = rsi_df[days:]\n",
    "\n",
    "    return rsi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsi_table test\n",
    "days = 14\n",
    "rsi_df = rsi_table (stock_prices, days)\n",
    "rsi_df.to_csv(\"resources/rsi.csv\")\n",
    "rsi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD method : Calculate the MACD indicator with its Signal line\n",
    "def macd_table(df, short_window, long_window, signal_window):\n",
    "    ''' Moving Average Convergence Divergence (MACD) \n",
    "        Returns a pd.DataFrame with MACD and its Signal line column appended\n",
    "        MACD formula = (12-day EMA - 26-day EMA)\n",
    "        Signal line = MACD 9-day EMA\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame - dataframe to be processed\n",
    "        short_ema : int() - short-term EMA for MACD calculation => default should be 12 days\n",
    "        long_ema : int() - long-term EMA for MACD calculation => defaultshould be 26 days\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        result_df : pd.DataFrame - dataframe with MACD and Signal line column appended, calcualted daily for \n",
    "        timeperiod specified by days\n",
    "    '''\n",
    "\n",
    "    # Filter datafrance to clumn \"close\" only to facilitate the calculs\n",
    "    stocks_close = df.iloc[:,df.columns.get_level_values(1)=='close']\n",
    "    stocks_close = stocks_close.swaplevel(0,1,axis=1)\n",
    "    \n",
    "    # Define a sub-function to calculate the MACD\n",
    "    def macd (price):\n",
    "        short_ema = price.ewm(span=short_window, adjust=False).mean()\n",
    "        long_ema = price.ewm(span=long_window, adjust=False).mean()\n",
    "        macd_value = short_ema - long_ema\n",
    "        return macd_value\n",
    "    \n",
    "    # Calculate the MACD and add it to a dataframe\n",
    "    macd = stocks_close.apply(macd)\n",
    "    macd.rename(columns={'close':'MACD'}, level=0, inplace=True)\n",
    "\n",
    "    # Calculate the Signal line value\n",
    "    signal = macd.ewm(span=9, adjust=False).mean()\n",
    "    signal.rename(columns={'MACD':'MACD_Signal'}, level=0, inplace=True)\n",
    "    \n",
    "    # Concatenate/append both indicators to a new dataframe\n",
    "    result_df = pd.concat([macd, signal], axis=1, join='inner')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD method test\n",
    "short_window = 12\n",
    "long_window = 26\n",
    "signal_window = 9\n",
    "combined_macd = macd_table(stock_prices, short_window, long_window, signal_window)\n",
    "combined_macd.to_csv(\"resources/macd.csv\")\n",
    "combined_macd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Bands method : \n",
    "def bbands_table(df, length, numstd):\n",
    "    '''Bollinger Bands (BB)\n",
    "    returns average, upper band, and lower band\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame - dataframe to be processed\n",
    "    lenght : int() - numer of prices we want to use to observe the average price \n",
    "    numstd : int() - number of Standard deviation we want to use to calculate the bands\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame - dataframe with RSI column appended, calcualted daily for \n",
    "    timeperiod specified by days\n",
    "    '''\n",
    "    \n",
    "    # Filter datafrance to clumn \"close\" only to facilitate the calculs\n",
    "    stocks_close = df.iloc[:,df.columns.get_level_values(1)=='close']\n",
    "    stocks_close = stocks_close.swaplevel(0,1,axis=1)\n",
    "\n",
    "\n",
    "    def bb_upband(price):\n",
    "        #avg = pd.stats.moments.rolling_mean(price,length)\n",
    "        avg = price.rolling(window= length).mean()\n",
    "        #std = pd.stats.moments.rolling_std(price,length)\n",
    "        std = price.rolling(window= length).std()\n",
    "\n",
    "        upband = avg + (std*numstd)\n",
    "        return np.round(upband,3)\n",
    "\n",
    "    def bb_dnband(price):\n",
    "        #avg = pd.stats.moments.rolling_mean(price,length)\n",
    "        avg = price.rolling(window= length).mean()\n",
    "        #std = pd.stats.moments.rolling_std(price,length)\n",
    "        std = price.rolling(window= length).std()\n",
    "\n",
    "        dnband = avg - (std*numstd)\n",
    "        return np.round(dnband,3)\n",
    "\n",
    "    bb_avg_df = stocks_close.rolling(window= length).mean()\n",
    "    bb_avg_df.rename(columns={'close':'BB_Avg'}, level=0, inplace=True)\n",
    "    \n",
    "    bb_upband_df = stocks_close.apply(bb_upband)\n",
    "    bb_upband_df.rename(columns={'close':'BB_Upband'}, level=0, inplace=True)\n",
    "\n",
    "    bb_dnband_df = stocks_close.apply(bb_upband)\n",
    "    bb_dnband_df.rename(columns={'close':'BB_Downband'}, level=0, inplace=True)\n",
    "\n",
    "    # Concatenate/append both values to the original dataframe\n",
    "    result_df = pd.concat([bb_avg_df, bb_dnband_df, bb_upband_df], axis=1, join='inner')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bollinger Band method test\n",
    "length = 30\n",
    "numstd = 2\n",
    "combined_bb = bbands_table(stock_prices, length, numstd)\n",
    "combined_bb.to_csv(\"resources/bb.csv\")\n",
    "combined_bb.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsi_trader(tickers_list : list(), \n",
    "               lower_level : int(), \n",
    "               upper_level : int(), \n",
    "               start_date : str(), \n",
    "               end_date : str(), \n",
    "               rsi_range : int()):\n",
    "    '''Returns a pd.DataFrame of a portoflio where position entry and exit are \n",
    "        determined by Relative Strength Index (RSI) values provided by the user.\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        tickers_list : list() - list of tickers to be traded\n",
    "        lower_level : int() - lower level of RSI provided by user\n",
    "        upper_level : int() - upper level of RSI provided by user\n",
    "        start_date : str() - analysis start date string \"YYYY-MM-DD\"\n",
    "        end_date : str() - analysis end date string \"YYYY-MM-DD\"\n",
    "        rsi_range : int() - numbers of days for RSI calcualtion\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        result_df : pd.DataFrame - RSI traded portfolio\n",
    "    '''\n",
    "    \n",
    "    # Get stock prices form Alpaca Trade API\n",
    "    stock_prices = stock_prices_from_api(tickers_list, start_date, end_date)\n",
    "    \n",
    "    # Collapse multi-index to yield a single-index df with 'close' prices\n",
    "    try:\n",
    "        formatted_stock_prices = stock_prices.xs('close', axis=1, level=1, drop_level=False).droplevel(1, axis=1)\n",
    "    except:\n",
    "        formatted_stock_prices = pd.DataFrame({'time' : [datetime.strptime('2020-01-01', \"%Y-%m-%d\")], 'close' : [0.0]})\n",
    "        print(\"RSI Portfolio Builder received an empty pd.DataFrame of stock prices\")\n",
    "        raise\n",
    "        \n",
    "    # Declare RSI df\n",
    "    rsi_df = pd.DataFrame()   \n",
    "    \n",
    "    # Declare arbitrary cash position df and seed it\n",
    "    cash_seed = 1000000.0\n",
    "    cash_position = {}\n",
    "    cash_position[0] = {'time' : formatted_stock_prices.index[0], 'close' : cash_seed}\n",
    "    \n",
    "    # Track long stock positions\n",
    "    long_stock_position_tracker = {}\n",
    "    for ticker in tickers_list:\n",
    "        long_stock_position_tracker[ticker] = False\n",
    "    \n",
    "    # Build RSI trader positions over time\n",
    "    ## iterate ticker colums\n",
    "    for ticker in tickers_list:\n",
    "        \n",
    "        ### Declate dict for stock positions\n",
    "        stock_seed = 0.0\n",
    "        stock_position = {}\n",
    "        stock_position[0] = {'time' : formatted_stock_prices.index[0], 'close' : stock_seed, 'rsi' : 0, 'stock_price' : 0, 'cash' : cash_seed/len(tickers_list)}\n",
    "        \n",
    "        ### generate df for ticker\n",
    "        ticker_df = pd.DataFrame(formatted_stock_prices[ticker]).reset_index()\n",
    "\n",
    "        # Calculate RSI\n",
    "        delta = ticker_df[ticker].diff()\n",
    "        move_up = delta.clip(lower=0)\n",
    "        move_down = -1*delta.clip(upper=0)\n",
    "        ema_up = move_up.ewm(com=rsi_range, adjust=False).mean()\n",
    "        ema_down = move_down.ewm(com=rsi_range, adjust=False).mean()\n",
    "        relative_strenght = ema_up/ema_down\n",
    "        \n",
    "        # add RSI to df\n",
    "        ticker_df['rsi'] = 100 - (100/(1 + relative_strenght))\n",
    "     \n",
    "        # Skip first 14 days\n",
    "        ticker_df = ticker_df.iloc[14:]\n",
    "           \n",
    "        #### iterate over the trading days\n",
    "        for day in range(len(ticker_df.index)):\n",
    "            ### get data for previous and current days and get RSI\n",
    "            date = ticker_df.iloc[day,:]['time']\n",
    "            stock_price = ticker_df.iloc[day,:][ticker]\n",
    "            previous_day_rsi  = float(ticker_df.iloc[day-1, 2])\n",
    "            current_day_rsi = float(ticker_df.iloc[day, 2])\n",
    "\n",
    "            #### Trade logic - Open Long Position\n",
    "            if previous_day_rsi < float(lower_level) and current_day_rsi > float(lower_level):\n",
    "\n",
    "                ##### Check if long stock -> pass\n",
    "                if long_stock_position_tracker[ticker] == True:\n",
    "                    ## Adjust position\n",
    "                    stock_position[day] = {'time' : date, 'close' : stock_position[day-1]['close'], 'rsi' : current_day_rsi,  'stock_price' : stock_price, 'cash' : stock_position[day-1]['cash']}\n",
    "\n",
    "\n",
    "                #### Check if not long stock -> Go long\n",
    "                elif long_stock_position_tracker[ticker] == False:\n",
    "                    # Long position entry triggered\n",
    "\n",
    "                    ## Adjust position\n",
    "                    stock_adj = (cash_seed/len(tickers_list))/stock_price\n",
    "                    cash_adj = 0\n",
    "\n",
    "                    stock_position[day] = {'time' : date, 'close' : stock_adj, 'rsi' : current_day_rsi,  'stock_price'  : stock_price, 'cash' : cash_adj}\n",
    "\n",
    "                    long_stock_position_tracker[ticker] = True\n",
    "\n",
    "            ### Trade Logic - Close Long Position\n",
    "            elif previous_day_rsi > float(upper_level) and current_day_rsi < float(upper_level):\n",
    "\n",
    "                #### Check if not long stock -> pass\n",
    "                if long_stock_position_tracker[ticker] == False:\n",
    "                    ## Adjust position\n",
    "                    try:\n",
    "                        stock_position[day] = {'time' : date, 'close' : stock_position[day-1]['close'], 'rsi' : current_day_rsi,  'stock_price' : stock_price, 'cash' : stock_position[day-1]['cash']}\n",
    "                    except:\n",
    "                        stock_position[day] = {'time' : date, 'close' : 0, 'rsi' : current_day_rsi,  'stock_price' : stock_price, 'cash' : cash_seed/len(tickers_list)}\n",
    "\n",
    "                #### Check if long stock -> Close long\n",
    "                if long_stock_position_tracker[ticker] == True:\n",
    "                    # Long position exit triggered\n",
    "                    ## Adjust cash position\n",
    "                    cash_adj = stock_position[day-1]['cash'] + stock_position[day-1]['close'] * stock_price\n",
    "                    stock_adj = 0\n",
    "\n",
    "                    stock_position[day] = {'time' : date, 'close' : stock_adj, 'rsi' : current_day_rsi,  'stock_price' : stock_price, 'cash' : cash_adj}\n",
    "\n",
    "                    long_stock_position_tracker[ticker] = False\n",
    "\n",
    "            ### Trade Logic - No Trade\n",
    "            else:\n",
    "                ## Adjust position\n",
    "                try:\n",
    "                    stock_position[day] = {'time' : date, 'close' : stock_position[day-1]['close'], 'rsi' : current_day_rsi,  'stock_price' : stock_price, \"cash\" : stock_position[day-1]['cash']}\n",
    "                except:\n",
    "                    stock_position[day] = {'time' : date, 'close' : 0, 'rsi' : current_day_rsi,  'stock_price'  : stock_price, 'cash' : cash_seed/len(tickers_list)}\n",
    "                \n",
    "        # Transpose stock_position_df   \n",
    "        stock_position_df = pd.DataFrame(stock_position).transpose()\n",
    "        \n",
    "        # Set index to tim\n",
    "        stock_position_df = stock_position_df.set_index('time')\n",
    "        \n",
    "        # Calculate stock_position_df positon value\n",
    "        stock_position_df[ticker] = (stock_position_df['close'] * stock_position_df['stock_price']) + stock_position_df['cash']\n",
    "        \n",
    "        # Concatentate stock_position_df into master df\n",
    "        rsi_df = pd.concat([rsi_df,stock_position_df[ticker]], axis='columns', join='outer')\n",
    "    \n",
    "    # Get total portfolio value\n",
    "    rsi_portfolio_sum = rsi_df.sum(axis=1)/cash_seed-1\n",
    "\n",
    "    return rsi_portfolio_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSI Trader method test\n",
    "tickers = ['DLR','EQIX', 'PRU']\n",
    "\n",
    "lower_level = 30\n",
    "upper_level = 70\n",
    "start_date = \"2020-05-01\"\n",
    "end_date = \"2021-05-01\"\n",
    "rsi_range = 14\n",
    "rsi_trader(tickers, lower_level, upper_level, start_date, end_date, rsi_range).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## FundamentalMethods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fundamental Data Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get stock fundamental data from FinnHub\n",
    "def generate_stock_fundamentals_from_finnhub(tickers_df):\n",
    "    '''Returns pd.DataFrame with fundamentals of tickers within tickers_df\n",
    "    \n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    tickers_df : pd.DataFrame - contains tickers for given index or sector under \n",
    "        the \"Symbol\" column which is the DataFrame key\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame - securities fundamental data\n",
    "    '''\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    for ticker in tickers_df['Symbol']:\n",
    "        fundamental_data = finnhub_data(ticker)\n",
    "        result_df = pd.concat([result_df, fundamental_data], axis='rows', join=\"outer\")\n",
    "        \n",
    "        \n",
    "    # Parse the dataframe\n",
    "    result_df = result_df.reset_index().set_index('symbol')\n",
    "    result_df = result_df.drop('metricType', 1)\n",
    "    result_df.columns = ['metric_type', 'metric', 'series']\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fundamental methods test\n",
    "generate_stock_fundamentals_from_finnhub(sp500_tickers.head(10)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Refresh stock fundamental data csv\n",
    "def refresh_fundamentals_csv(tickers_df):\n",
    "    '''Helper method - returns pd.DataFrame with fundamentals of tickers within tickers_df\n",
    "    and/or calls to generate a refreashed dataset.\n",
    "    \n",
    "    Generates a CSV file with updated Fundamental values\n",
    "    \n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    tickers_df : pd.DataFrame - contains tickers for given index or sector under \n",
    "        the \"Symbol\" column which is the DataFrame key\n",
    "    '''\n",
    "    result_df = generate_stock_fundamentals_from_finnhub(tickers_df)\n",
    "    result_df.to_csv(\"resources/fundamental_data.csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fundamental data filter\n",
    "def fundamental_data_query(tickers_df, stock_fundamentals_df, fundamental_indicator_keys):\n",
    "    '''Returns a pd.DataFrame of fundamental data filtered by user input range\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tickers_df : pd.DataFrame - dataframe to be processed, contains tickers\n",
    "    fundamental_indicator_key : str() - keyword for fundamental indicator requested\n",
    "    \n",
    "        Fundamental indicator keys ->\n",
    "        \n",
    "        P/E Ratio : [pe_ratio]\n",
    "        EPS (Earnings per Share) : [eps]\n",
    "        Annual Dividend : [dividend]\n",
    "        Beta (vs. S&P 500) : [beta]\n",
    "        EBIDT : [ebidt]\n",
    "        Quick Ratio : [quick_ratio]\n",
    "        3 Year Revenue Growth : [rev_growth]\n",
    "        Free Cash Flow : [cash_flow]\n",
    "    \n",
    "    lower_bound : int() or float() - lower bound for fundamental value filter, default = -1000000\n",
    "    upper_bound : int() or float() - upper bound for fundamental value filter, default = 1000000\n",
    "     \n",
    "     \n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame - dataframe with ticker and filtered fundamental data\n",
    "    '''\n",
    "\n",
    "    fund_indicators_dict = {\n",
    "        'pe_ratio' : 'peNormalizedAnnual',\n",
    "        'eps' : 'epsNormalizedAnnual',\n",
    "        'dividend' : 'dividendsPerShareTTM',\n",
    "        'beta' : 'beta',\n",
    "        'ebidt' : 'ebitdPerShareTTM',\n",
    "        'quick_ratio' : 'quickRatioAnnual',\n",
    "        'rev_growth' : 'revenueGrowth3Y',\n",
    "        'free_cash_flow' : 'freeCashFlowAnnual'   \n",
    "    }\n",
    "\n",
    "    # Declare result_df\n",
    "    result_df = pd.DataFrame()\n",
    "    \n",
    "    # Declate tickers list\n",
    "    tickers_list = tickers_df['Symbol']\n",
    "    \n",
    "    # Declare fundamental data df and filter by ticker df\n",
    "    data_df = stock_fundamentals_df[stock_fundamentals_df.symbol.isin(tickers_list)]\n",
    "    data_df = data_df.set_index(['symbol'])\n",
    "    \n",
    "    # Extract requested fundamental data\n",
    "    for ind in fundamental_indicator_keys:\n",
    "        df = data_df[data_df['metric_type'] == fund_indicators_dict[ind]]\n",
    "        result_df = pd.concat([result_df, df], axis = 1, join = 'outer')\n",
    "    \n",
    "        # Clean up df\n",
    "        result_df = result_df.drop(columns = ['metric_type', 'series'])\n",
    "        result_df = result_df.rename(columns = {'symbol' : 'ticker', \n",
    "                                'metric' : ind})\n",
    "        \n",
    "            # Convert all df values to numeric\n",
    "        result_df[ind] = result_df[ind].apply(pd.to_numeric)\n",
    "\n",
    "    \n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fundamental data filter test\n",
    "fundamental_values = fundamental_data_query(sp500_tickers, stock_fundamentals_df, ['eps', 'pe_ratio', 'dividend','ebidt','quick_ratio','rev_growth','free_cash_flow'])\n",
    "fundamental_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fundamental Portfolio Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter stocks by Dashboard selection\n",
    "def filter_stocks_by_fundamentals(pe_range: tuple, \n",
    "                                  eps_range: tuple,\n",
    "                                  dividend_range: tuple):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    # Filter PE and EPS\n",
    "    min_pe = pe_range[0]\n",
    "    max_pe = pe_range[1]\n",
    "    \n",
    "    min_eps = eps_range[0]\n",
    "    max_eps = eps_range[1]\n",
    "    \n",
    "    min_dividend = dividend_range[0]\n",
    "    max_dividend = dividend_range[1]\n",
    "    \n",
    "    # Filer fundamental_values dataframe by value range\n",
    "    result_df = fundamental_values[(fundamental_values['eps'] >= min_eps) & \n",
    "                                   (fundamental_values['eps'] <= max_eps) & \n",
    "                                   \n",
    "                                   (fundamental_values['pe_ratio'] >= min_pe) & \n",
    "                                   (fundamental_values['pe_ratio'] <= max_pe) &\n",
    "                                   \n",
    "                                   (fundamental_values['dividend'] >= min_dividend) & \n",
    "                                   (fundamental_values['dividend'] <= max_dividend)\n",
    "                                  ]\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter stocks by Dashboard selection test\n",
    "pe_range = (0,200)\n",
    "eps_range = (0,200)\n",
    "dividend_range = (4, 10)\n",
    "\n",
    "filter_stocks_by_fundamentals(pe_range, eps_range, dividend_range).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of dates between two user selected dates\n",
    "def list_of_dates_between_two_dates(start_date: str,\n",
    "                                    end_date: str):  \n",
    "    '''\n",
    "    Helper function to ger a range of dates between two dates\n",
    "    '''\n",
    "    return (pd.date_range(start_date, end_date-timedelta(days=1), freq='d').strftime(\"%Y-%m-%d\").to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list_of_dates_between_two_dates test\n",
    "start_date = datetime.strptime(\"2020-01-02\", '%Y-%m-%d')\n",
    "end_date = datetime.strptime(\"2020-02-02\", '%Y-%m-%d')\n",
    "\n",
    "list_of_dates_between_two_dates(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build fundamental portfolio\n",
    "def get_fundamental_portfolio(ticker_list,\n",
    "                                start_date: str = \"2020-01-01\", \n",
    "                                end_date: str = \"2021-05-01\"):\n",
    "    '''Returns pd.DataFrame weighted cumulative product portfolio\n",
    "    \n",
    "    ...\n",
    "    Parameters\n",
    "    ----------\n",
    "    ticker_list : list - contains tickers to be processed\n",
    "    start_date : str() - analysis start date string \"YYYY-MM-DD\"\n",
    "    end_date : str() - analysis end date string \"YYYY-MM-DD\"\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    result_df : pd.DataFrame - dataframe with ticker and filtered fundamental data\n",
    "    '''\n",
    "    \n",
    "    # Get stock prices for given stocks \n",
    "    stock_prices = stock_prices_from_api(ticker_list, start_date, end_date)\n",
    "    \n",
    "    idx = pd.IndexSlice\n",
    "    index = list(stock_prices.transpose().index.get_level_values(0))\n",
    "    try:\n",
    "        formatted_stock_prices = stock_prices.xs('close', axis=1, level=1, drop_level=False).droplevel(1, axis=1)\n",
    "    except:\n",
    "        formatted_stock_prices = pd.DataFrame({'time' : ['2020_01_01'], 'close' : [0.0]})\n",
    "    \n",
    "    # For equal weight portfolio\n",
    "    ntickers = len(ticker_list)\n",
    "    weights = np.full(ntickers, (1.0 / ntickers))\n",
    "    \n",
    "    \n",
    "    equal_weighted_portfolio = formatted_stock_prices.pct_change().dot(weights).cumsum().dropna()\n",
    "        \n",
    "    return equal_weighted_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build fundamental portfolio test\n",
    "portfolio = pd.DataFrame(get_fundamental_portfolio(['AAPL','MSFT','TSLA'], \"2020-01-01\", \"2021-05-01\"))\n",
    "portfolio = portfolio.rename(columns = {0 : 'close'})\n",
    "portfolio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fundumental portfolio plot\n",
    "portfolio.hvplot(x='time',\n",
    "                 y='close',\n",
    "                 title='Fundamental Portfolio',\n",
    "                 ylabel='Portfolio Returns, %',\n",
    "                 height=700,\n",
    "                 legend='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Diplay technical analysis plot\n",
    "def display_technical_chart(ticker, ohlcv, rsi, macd, start_date, end_date):\n",
    "    '''Ploting chart\n",
    "        Returns 3 charts: RSI, Price/volume and MACD\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        ticker : str() - symbol of teh ticker we select\n",
    "        ohlcv : pd.DataFrame - initial dataframe to be processed with open / high / low / close / volume\n",
    "        rsi : pd.DataFrame - dataframe to be processed with RSI\n",
    "        macd : pd.DataFrame - dataframe to be processed with MACD\n",
    "\n",
    "        start_date : str() - string with date in following format YYYY-MM-DD\n",
    "        end_date : str() - string with date in following format YYYY-MM-DD\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        3 charts\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ############# create a new DF filtered on one ticker ###############\n",
    "    \n",
    "    # Swap column levels for RSI_DF and MACD_DF to make sure we have the ticker in level 0\n",
    "    rsi_df= rsi.swaplevel(0,1,axis=1)\n",
    "    \n",
    "    \n",
    "    rsi_df_sliced= rsi_df.loc[start_date:end_date,ticker]\n",
    "    macd_df= macd.swaplevel(0,1,axis=1)\n",
    "    macd_df_sliced= macd_df.loc[start_date:end_date,ticker]\n",
    "    ohlcv_df_sliced=ohlcv.loc[start_date:end_date,ticker]\n",
    "    \n",
    "    # Concat the dfs\n",
    "    chart_ta_df = pd.concat([ohlcv_df_sliced, rsi_df_sliced, macd_df_sliced], axis=1, join='inner')\n",
    "\n",
    "    \n",
    "    #################### Chart ######################\n",
    "    \n",
    "    \n",
    "    # Create the figure\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "   \n",
    "    # Create the first subplot = Price\n",
    "    ax1 = plt.subplot2grid((6,4), (1,0), rowspan=4, colspan=4)\n",
    "    ax1 = chart_ta_df['close'].plot(color='b', label='Price')\n",
    "    ax1.grid(True, color='c', linestyle='--')\n",
    "    ax1.yaxis.label.set_color(\"k\")\n",
    "    ax1.tick_params(axis='y', colors='k')\n",
    "    ax1.tick_params(axis='x', colors='k')\n",
    "    ax1.set_facecolor('w')\n",
    "    plt.ylabel('Stock price and Volume')\n",
    "   \n",
    "    # Add the volume within the same subplot\n",
    "    # Retrieve volumes into a list\n",
    "    volume = chart_ta_df['volume']\n",
    "    # Share the same x-axis\n",
    "    ax1v= ax1.twinx()\n",
    "    ax1v.fill_between(chart_ta_df.index, volume,0, color='darkturquoise', alpha=0.5, label='Volume')\n",
    "    # To avoid having a second grid overlaping the first one\n",
    "    ax1v.grid(False)\n",
    "    # Set the limit for the second y-axis and make it look smaller by multiplying the max volume\n",
    "    ax1v.set_ylim(0, 3*volume.max())\n",
    "    ax1v.axes.yaxis.set_ticklabels([])\n",
    "    ax1v.tick_params(axis='y', colors='k')\n",
    "    ax1v.yaxis.label.set_color(\"k\")\n",
    "    ax1v.spines['bottom'].set_color('midnightblue')\n",
    "    ax1v.spines['top'].set_color('midnightblue')\n",
    "    ax1v.spines['left'].set_color('midnightblue')\n",
    "    ax1v.spines['right'].set_color('midnightblue')\n",
    "    ax1v.legend()\n",
    "\n",
    "    # Create a second subplot for the RSI\n",
    "    ax0 = plt.subplot2grid((6,4), (0,0), sharex=ax1, rowspan=1, colspan=4)      \n",
    "    ax0 = chart_ta_df['RSI'].plot(color='r')\n",
    "    ax0.axhline(70, color='m')\n",
    "    ax0.axhline(30, color='m')\n",
    "    ax0.set_yticks([30,70])\n",
    "    ax0.yaxis.label.set_color(\"w\")\n",
    "    ax0.tick_params(axis='y', colors='k')\n",
    "    ax0.tick_params(axis='x', colors='k')\n",
    "    ax0.grid(True, color='c', linestyle='--')\n",
    "    ax0.set_facecolor('w')\n",
    "    ax0.spines['bottom'].set_color('midnightblue')\n",
    "    ax0.spines['top'].set_color('midnightblue')\n",
    "    ax0.spines['left'].set_color('midnightblue')\n",
    "    ax0.spines['right'].set_color('midnightblue')\n",
    "    plt.ylabel('RSI')\n",
    "\n",
    "    # Create a third subplot for the MACD\n",
    "    ax2= plt.subplot2grid((6,4), (5,0), sharex=ax1, rowspan=1, colspan=4)\n",
    "    ax2= chart_ta_df['MACD'].plot(color='limegreen', linewidth=2, label='MACD')\n",
    "    ax2.tick_params(axis='x', colors='k')\n",
    "    ax2.tick_params(axis='y', colors='k')\n",
    "    ax2.grid(True, color='c', linestyle='--')\n",
    "    ax2.set_facecolor('w')\n",
    "    ax2.spines['bottom'].set_color('midnightblue')\n",
    "    ax2.spines['top'].set_color('midnightblue')\n",
    "    ax2.spines['left'].set_color('midnightblue')\n",
    "    ax2.spines['right'].set_color('midnightblue')\n",
    "    plt.ylabel('MACD', color='k')\n",
    "   \n",
    "    # Add the Signal line to the same subplot\n",
    "    # share the same x-axis\n",
    "    ax_signal= ax2.twinx()\n",
    "    ax_signal= chart_ta_df['MACD_Signal'].plot(color='orange',linestyle='--', label='Signal')\n",
    "    ax_signal.spines['bottom'].set_color('midnightblue')\n",
    "    ax_signal.spines['top'].set_color('midnightblue')\n",
    "    ax_signal.spines['left'].set_color('midnightblue')\n",
    "    ax_signal.spines['right'].set_color('midnightblue')\n",
    "    plt.legend()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display technical chart test\n",
    "stock_prices_for_technical_chart = stock_prices_from_api([\"TSLA\"],\n",
    "                                                        \"2020-01-01\",\n",
    "                                                        \"2021-01-01\")\n",
    "rsi_df = rsi_table(stock_prices_for_technical_chart, 14)\n",
    "\n",
    "macd_df = macd_table(stock_prices_for_technical_chart, 12, 26, 9)\n",
    "\n",
    "technical_chart_panel = pn.pane.Matplotlib(display_technical_chart('TSLA', \n",
    "                                                         stock_prices_for_technical_chart, \n",
    "                                                         rsi_df, \n",
    "                                                         macd_df,\n",
    "                                                         \"2020-01-01\",\n",
    "                                                         \"2021-01-01\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
